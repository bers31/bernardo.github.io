{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7152cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "class BuzzerDetector:\n",
    "    def __init__(self):\n",
    "        # Daftar manual buzzer yang sudah dikenal (bisa ditambah sesuai kebutuhan)\n",
    "        self.manual_buzzer_list = [\n",
    "            'buzzerpolitik1', 'akunbuzzer', 'politikbuzz',\n",
    "            # Tambahkan username buzzer yang sudah dikenal\n",
    "        ]\n",
    "\n",
    "        # Stopwords bahasa Indonesia\n",
    "        self.stopwords = {\n",
    "            'yang', 'ini', 'itu', 'dan', 'di', 'ke', 'dari', 'untuk', 'dengan', 'pada',\n",
    "            'adalah', 'akan', 'telah', 'sudah', 'ada', 'tidak', 'juga', 'atau', 'bisa',\n",
    "            'dapat', 'harus', 'karena', 'saya', 'kamu', 'dia', 'kita', 'mereka', 'kami',\n",
    "            'satu', 'dua', 'tiga', 'banyak', 'semua', 'beberapa', 'sebagai', 'seperti',\n",
    "            'jika', 'kalau', 'ketika', 'saat', 'waktu', 'setelah', 'sebelum', 'hingga',\n",
    "            'sampai', 'antara', 'dalam', 'luar', 'atas', 'bawah', 'depan', 'belakang',\n",
    "            'kiri', 'kanan', 'tengah', 'mana', 'dimana', 'bagaimana', 'mengapa', 'kenapa',\n",
    "            'siapa', 'apa', 'kapan', 'berapa', 'masing', 'setiap', 'tiap', 'per', 'nya',\n",
    "            'mu', 'ku', 'lah', 'kah', 'pun', 'tah', 'dong', 'sih', 'ya', 'yah', 'deh',\n",
    "            'lho', 'kok', 'wah', 'aduh', 'astaga', 'duh', 'ih', 'eh', 'oh', 'ah', 'hai',\n",
    "            'halo', 'oke', 'ok', 'baik', 'bagus', 'buruk', 'jelek', 'cantik', 'ganteng',\n",
    "            'kecil', 'besar', 'tinggi', 'rendah', 'panjang', 'pendek', 'lebar', 'sempit', 'aja'\n",
    "        }\n",
    "\n",
    "        # Kata kunci untuk deteksi buzzer di bio/description\n",
    "        self.buzzer_keywords = [\n",
    "            'buzzer', 'paid promote', 'endorse', 'marketing', 'influencer',\n",
    "            'promosi', 'iklan', 'sponsor', 'jasa', 'followers', 'engagement'\n",
    "        ]\n",
    "\n",
    "        # Kata kunci untuk deteksi tweet promosi/iklan (diperluas dengan variasi)\n",
    "        self.promo_keywords = [\n",
    "            'promo', 'diskon', 'sale', 'beli', 'jual', 'order', 'wa ', 'whatsapp',\n",
    "            'dm ', 'link bio', 'followers', 'likes', 'retweet', 'rt back',\n",
    "            'follow back', 'followback', 'mutual', 'base', 'admin', 'dropship',\n",
    "            'reseller', 'supplier', 'grosir', 'ecer', 'cod', 'transfer', 'bayar',\n",
    "            'harga', 'murah', 'free', 'bonus', 'hadiah', 'voucher',\n",
    "            'kupon', 'cashback', 'diskon', 'potongan', 'hemat', 'terbatas',\n",
    "            'stok', 'ready', 'available', 'sold', 'habis', 'ludes'\n",
    "        ]\n",
    "\n",
    "        # Pattern regex untuk mendeteksi variasi ejaan promosi (leetspeak)\n",
    "        self.promo_patterns = [\n",
    "            r'pr[0o]m[0o]',  # promo, pr0mo, prom0, pr0m0\n",
    "            r'd[i1]sc[0o]un[t7]',  # discount, d1scoun7, disc0unt\n",
    "            r'[!@#$%]*promo[!@#$%]*',  # !promo!, @promo@, etc\n",
    "            r'[!@#$%]*diskon[!@#$%]*',  # !diskon!, @diskon@, etc\n",
    "            r'j[4a]w[4a]l',  # jawal (jual)\n",
    "            r'b[3e]l[i1]',  # beli, b3li, bel1\n",
    "            r'mur[4a]h',  # murah, mur4h\n",
    "            r'c[0o]d',  # cod, c0d\n",
    "            r'w[4a]',  # wa, w4\n",
    "        ]\n",
    "\n",
    "        # Kata kunci relevan untuk topik keracunan MBG (diperluas)\n",
    "        self.relevant_keywords = [\n",
    "            'mbg', 'keracunan', 'racun', 'makanan', 'minuman', 'jajanan',\n",
    "            'kadaluarsa', 'expired', 'kesehatan', 'sakit', 'mual', 'muntah',\n",
    "            'diare', 'pusing', 'keracunan makanan', 'food poisoning',\n",
    "            'bpom', 'dinkes', 'puskesmas', 'rumah sakit', 'rs', 'dokter',\n",
    "            'obat', 'antibiotik', 'infus', 'rawat', 'korban', 'pasien',\n",
    "            'gejala', 'demam', 'lemas', 'dehidrasi', 'perut', 'lambung',\n",
    "            'usus', 'pencernaan', 'bakteri', 'virus', 'kontaminasi',\n",
    "            'higiene', 'sanitasi', 'kebersihan', 'cuci tangan'\n",
    "        ]\n",
    "\n",
    "    def remove_stopwords(self, text: str) -> str:\n",
    "        \"\"\"Menghapus stopwords dari teks\"\"\"\n",
    "        if pd.isna(text) or not isinstance(text, str):\n",
    "            return \"\"\n",
    "\n",
    "        # Bersihkan teks dari karakter khusus dan angka berlebihan\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text.lower())\n",
    "        text = re.sub(r'\\d+', '', text)  # Hapus angka\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()  # Normalize whitespace\n",
    "\n",
    "        # Split dan hapus stopwords\n",
    "        words = text.split()\n",
    "        filtered_words = [word for word in words if word not in self.stopwords and len(word) > 2]\n",
    "\n",
    "        return ' '.join(filtered_words)\n",
    "\n",
    "    def detect_promo_patterns(self, text: str) -> bool:\n",
    "        \"\"\"Deteksi pola promosi menggunakan regex untuk menangani variasi ejaan\"\"\"\n",
    "        if pd.isna(text) or not isinstance(text, str):\n",
    "            return False\n",
    "\n",
    "        text_lower = text.lower()\n",
    "\n",
    "        # Cek pattern regex\n",
    "        for pattern in self.promo_patterns:\n",
    "            if re.search(pattern, text_lower):\n",
    "                return True\n",
    "\n",
    "        # Cek keyword biasa\n",
    "        for keyword in self.promo_keywords:\n",
    "            if keyword in text_lower:\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def detect_buzzer_by_frequency(self, df_filtered: pd.DataFrame, min_tweets: int = 5, max_tweets_per_day: int = 15) -> List[str]:\n",
    "        tweet_counts = df_filtered['username'].value_counts()\n",
    "\n",
    "        # Filter akun dengan tweet setidaknya min_tweets\n",
    "        high_frequency_users = tweet_counts[tweet_counts >= min_tweets].index.tolist()\n",
    "\n",
    "        buzzer_candidates = []\n",
    "        if 'created_at' in df_filtered.columns:\n",
    "            # Pastikan kolom created_at sudah dalam tipe datetime\n",
    "            if isinstance(df_filtered['created_at'].iloc[0], str):\n",
    "                df_filtered['created_at'] = pd.to_datetime(df_filtered['created_at'], errors='coerce')\n",
    "\n",
    "            for username in high_frequency_users:\n",
    "                user_tweets = df_filtered[df_filtered['username'] == username]['created_at']\n",
    "                user_tweets = user_tweets.dropna()\n",
    "\n",
    "                if len(user_tweets) > 0:\n",
    "                    # Hitung rata-rata tweet per hari\n",
    "                    daily_counts = user_tweets.dt.date.value_counts()\n",
    "\n",
    "                    # Jika ada hari dengan tweet > max_tweets_per_day, tandai sebagai buzzer\n",
    "                    if (daily_counts > max_tweets_per_day).any():\n",
    "                        buzzer_candidates.append(username)\n",
    "\n",
    "                    # Tambahan: cek konsistensi posting (buzzer biasanya posting secara konsisten)\n",
    "                    if len(daily_counts) > 1:\n",
    "                        std_daily = daily_counts.std()\n",
    "                        mean_daily = daily_counts.mean()\n",
    "                        # Jika variasi posting sangat rendah (terlalu konsisten), mungkin bot\n",
    "                        if std_daily < 1 and mean_daily > 5:\n",
    "                            buzzer_candidates.append(username)\n",
    "\n",
    "        return list(set(buzzer_candidates))\n",
    "\n",
    "    def detect_buzzer_by_content(self, df_filtered: pd.DataFrame) -> List[str]:\n",
    "        \"\"\"Deteksi buzzer berdasarkan konten tweet (full_text) dengan pattern matching\"\"\"\n",
    "        buzzer_candidates = []\n",
    "\n",
    "        # Deteksi berdasarkan konten tweet yang bersifat promosi\n",
    "        for _, row in df_filtered.iterrows():\n",
    "            if self.detect_promo_patterns(row['full_text']):\n",
    "                buzzer_candidates.append(row['username'])\n",
    "\n",
    "        return list(set(buzzer_candidates))\n",
    "\n",
    "    def detect_buzzer_by_network(self, df_filtered: pd.DataFrame, min_connections: int = 10) -> List[str]:\n",
    "        \"\"\"Deteksi buzzer berdasarkan pola jaringan (high centrality)\"\"\"\n",
    "        buzzer_candidates = []\n",
    "\n",
    "        # Buat graf untuk reply-network\n",
    "        G = nx.DiGraph()\n",
    "        for _, row in df_filtered.iterrows():\n",
    "            if pd.notna(row['username']) and pd.notna(row['in_reply_to_screen_name']):\n",
    "                G.add_edge(row['username'], row['in_reply_to_screen_name'])\n",
    "\n",
    "        if len(G.nodes()) > min_connections:\n",
    "            try:\n",
    "                in_degree_centrality = nx.in_degree_centrality(G)\n",
    "                out_degree_centrality = nx.out_degree_centrality(G)\n",
    "\n",
    "                # Cari node dengan centrality di atas persentil ke-90 (lebih ketat dari 95)\n",
    "                if len(in_degree_centrality) > 0:\n",
    "                    thresh_in = np.percentile(list(in_degree_centrality.values()), 90)\n",
    "                    thresh_out = np.percentile(list(out_degree_centrality.values()), 90)\n",
    "\n",
    "                    high_in_degree = [node for node, cent in in_degree_centrality.items() if cent > thresh_in]\n",
    "                    high_out_degree = [node for node, cent in out_degree_centrality.items() if cent > thresh_out]\n",
    "\n",
    "                    buzzer_candidates.extend(high_in_degree + high_out_degree)\n",
    "            except:\n",
    "                # Jika terjadi error dalam perhitungan centrality\n",
    "                pass\n",
    "\n",
    "        return list(set(buzzer_candidates))\n",
    "\n",
    "    def detect_irrelevant_content(self, df_filtered: pd.DataFrame) -> List[int]:\n",
    "        \"\"\"Deteksi tweet yang tidak relevan dengan topik keracunan MBG (dengan stopword removal)\"\"\"\n",
    "        irrelevant_indices = []\n",
    "\n",
    "        for idx, row in df_filtered.iterrows():\n",
    "            # Terapkan stopword removal\n",
    "            cleaned_text = self.remove_stopwords(row['full_text'])\n",
    "            original_text = str(row['full_text']).lower()\n",
    "\n",
    "            # Cek relevansi dengan kata kunci di teks yang sudah dibersihkan\n",
    "            relevant_count = sum(1 for keyword in self.relevant_keywords if keyword in cleaned_text)\n",
    "\n",
    "            # Cek juga di teks asli untuk keyword yang mungkin terpotong\n",
    "            relevant_count_orig = sum(1 for keyword in self.relevant_keywords if keyword in original_text)\n",
    "\n",
    "            total_relevant = max(relevant_count, relevant_count_orig)\n",
    "\n",
    "            # Jika tidak ada kata kunci relevan, atau tweet sangat pendek\n",
    "            if total_relevant == 0 or len(cleaned_text.split()) < 3:\n",
    "                # Cek apakah ini tweet promosi/spam\n",
    "                if self.detect_promo_patterns(original_text):\n",
    "                    irrelevant_indices.append(idx)\n",
    "                elif len(original_text.split()) < 5:  # Tweet terlalu pendek\n",
    "                    irrelevant_indices.append(idx)\n",
    "                elif total_relevant == 0:  # Tidak relevan sama sekali\n",
    "                    irrelevant_indices.append(idx)\n",
    "\n",
    "        return irrelevant_indices\n",
    "\n",
    "    def clean_text_full(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Membersihkan teks secara menyeluruh:\n",
    "        1. Ubah ke lowercase\n",
    "        2. Hapus token 'RT ' di awal (jika tweet retweet)\n",
    "        3. Hapus URL mulai dengan http:// atau https://\n",
    "        4. Hapus mention @username\n",
    "        5. Hapus hashtag #topik\n",
    "        6. Hapus emoji/simbol Unicode (rentang umum)\n",
    "        7. Hapus angka\n",
    "        8. Hapus tanda baca / karakter non-alfabet\n",
    "        9. Normalize spasi\n",
    "        10. Remove stopwords\n",
    "        \"\"\"\n",
    "        if pd.isna(text) or not isinstance(text, str):\n",
    "            return \"\"\n",
    "\n",
    "        # 1. lowercase\n",
    "        t = text.lower()\n",
    "\n",
    "        # 2. hapus \"rt \" di awal (retweet indicator)\n",
    "        t = re.sub(r'^rt\\s+', '', t)\n",
    "\n",
    "        # 3. hapus URL\n",
    "        t = re.sub(r'http\\S+', ' ', t)       # http://… atau https://…\n",
    "        t = re.sub(r'www\\.\\S+', ' ', t)      # www.domain…\n",
    "\n",
    "        # 4. hapus mention\n",
    "        t = re.sub(r'@\\w+', ' ', t)\n",
    "\n",
    "        # 5. hapus hashtag (tetap ambil kata di dalamnya, tapi di sini kita buang seluruh #tag)\n",
    "        t = re.sub(r'#\\w+', ' ', t)\n",
    "\n",
    "        # 6. hapus emoji/simbol Unicode (rentang umum)\n",
    "        #    Ini pola umum untuk sebagian emoji; mungkin tidak meng-cover semua,\n",
    "        #    tapi cukup untuk kebanyakan emoji di rentang \\U0001F600 - \\U0001F6FF (emoticon, dingbats)\n",
    "        emoji_pattern = re.compile(\n",
    "            \"[\"\n",
    "            \"\\U0001F600-\\U0001F64F\"  # emoticon\n",
    "            \"\\U0001F300-\\U0001F5FF\"  # simbol & pictograph\n",
    "            \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            \"\\U0001F1E0-\\U0001F1FF\"  # flag\n",
    "            \"\\u2600-\\u26FF\"          # miscellaneous symbols\n",
    "            \"\\u2700-\\u27BF\"          # dingbats\n",
    "            \"]+\",\n",
    "            flags=re.UNICODE\n",
    "        )\n",
    "        t = emoji_pattern.sub(' ', t)\n",
    "\n",
    "        # 7. hapus angka\n",
    "        t = re.sub(r'\\d+', ' ', t)\n",
    "\n",
    "        # 8. hapus tanda baca / non-alfabet\n",
    "        #    Sisakan hanya huruf a–z dan spasi\n",
    "        t = re.sub(r'[^a-z\\s]', ' ', t)\n",
    "\n",
    "        # 9. normalize whitespace (ganti multiple spasi → satu spasi, lalu strip)\n",
    "        t = re.sub(r'\\s+', ' ', t).strip()\n",
    "\n",
    "        # 10. hapus stopwords\n",
    "        t = self.remove_stopwords(t)\n",
    "\n",
    "        return t\n",
    "\n",
    "    def comprehensive_filter(self, df_filtered: pd.DataFrame, verbose: bool = True) -> Tuple[pd.DataFrame, Dict]:\n",
    "        \"\"\"Filtering komprehensif menggunakan semua metode\"\"\"\n",
    "        return df_filtered['full_text'].apply(self.clean_text_full)\n",
    "        if verbose:\n",
    "            print(\"=== COMPREHENSIVE BUZZER DETECTION & FILTERING ===\")\n",
    "            print(f\"Jumlah tweet awal: {len(df_filtered)}\")\n",
    "\n",
    "        # Simpan jumlah awal untuk perhitungan persentase\n",
    "        initial_count = len(df_filtered)\n",
    "\n",
    "        # 1. Manual buzzer list (jika ada)\n",
    "        manual_buzzers = [user for user in self.manual_buzzer_list if user in df_filtered['username'].values]\n",
    "\n",
    "        # 2. Frequency-based detection (parameter yang sudah disesuaikan)\n",
    "        frequency_buzzers = self.detect_buzzer_by_frequency(df_filtered, min_tweets=8, max_tweets_per_day=15)\n",
    "\n",
    "        # 3. Content-based detection (dengan pattern matching yang lebih canggih)\n",
    "        content_buzzers = self.detect_buzzer_by_content(df_filtered)\n",
    "\n",
    "        # 4. Network-based detection\n",
    "        network_buzzers = self.detect_buzzer_by_network(df_filtered)\n",
    "\n",
    "        # 5. Irrelevant content detection (dengan stopword removal)\n",
    "        irrelevant_indices = self.detect_irrelevant_content(df_filtered)\n",
    "\n",
    "        # Gabungkan semua buzzer candidates\n",
    "        all_buzzers = list(set(manual_buzzers + frequency_buzzers + content_buzzers + network_buzzers))\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\nBuzzer Detection Results:\")\n",
    "            print(f\"- Manual buzzer list: {len(manual_buzzers)} users\")\n",
    "            print(f\"- Frequency-based: {len(frequency_buzzers)} users (min_tweets=5, max_per_day=15)\")\n",
    "            print(f\"- Content-based: {len(content_buzzers)} users (with pattern matching)\")\n",
    "            print(f\"- Network-based: {len(network_buzzers)} users\")\n",
    "            print(f\"- Total unique buzzers: {len(all_buzzers)} users\")\n",
    "            print(f\"- Irrelevant content: {len(irrelevant_indices)} tweets (with stopword removal)\")\n",
    "\n",
    "        # Filter buzzer accounts\n",
    "        df_no_buzzers = df_filtered[~df_filtered['username'].isin(all_buzzers)].copy()\n",
    "\n",
    "        # Filter irrelevant content\n",
    "        df_final = df_no_buzzers.drop(index=irrelevant_indices, errors='ignore').reset_index(drop=True)\n",
    "\n",
    "        df_final['cleaned_text'] = df_final['full_text'].apply(self.clean_text_full)\n",
    "\n",
    "        if verbose:\n",
    "            buzzer_removed = initial_count - len(df_no_buzzers)\n",
    "            content_removed = len(df_no_buzzers) - len(df_final)\n",
    "            total_removed = initial_count - len(df_final)\n",
    "\n",
    "            print(f\"\\nFiltering Results:\")\n",
    "            print(f\"- Tweets removed by buzzer filter: {buzzer_removed}\")\n",
    "            print(f\"- Tweets removed by irrelevant content filter: {content_removed}\")\n",
    "            print(f\"- Total tweets removed: {total_removed}\")\n",
    "            print(f\"- Tweets remaining: {len(df_final)}\")\n",
    "            print(f\"- Total reduction percentage: {total_removed / initial_count * 100:.2f}%\")\n",
    "\n",
    "        return df_final, {\n",
    "            'manual_buzzers': manual_buzzers,\n",
    "            'frequency_buzzers': frequency_buzzers,\n",
    "            'content_buzzers': content_buzzers,\n",
    "            'network_buzzers': network_buzzers,\n",
    "            'all_buzzers': all_buzzers,\n",
    "            'irrelevant_indices': irrelevant_indices,\n",
    "            'stats': {\n",
    "                'initial_count': initial_count,\n",
    "                'buzzer_removed': len(df_filtered) - len(df_no_buzzers),\n",
    "                'content_removed': len(df_no_buzzers) - len(df_final),\n",
    "                'final_count': len(df_final)\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d64d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        conversation_id_str                      created_at  favorite_count  \\\n",
      "count          5.060000e+02                             506      506.000000   \n",
      "unique                  NaN                             505             NaN   \n",
      "top                     NaN  Mon May 12 00:30:25 +0000 2025             NaN   \n",
      "freq                    NaN                               2             NaN   \n",
      "mean           1.920475e+18                             NaN      159.171937   \n",
      "std            7.510780e+15                             NaN     3187.178635   \n",
      "min            1.757999e+18                             NaN        0.000000   \n",
      "25%            1.920719e+18                             NaN        0.000000   \n",
      "50%            1.921012e+18                             NaN        0.000000   \n",
      "75%            1.921235e+18                             NaN        1.000000   \n",
      "max            1.921740e+18                             NaN    71432.000000   \n",
      "\n",
      "                                                full_text        id_str  \\\n",
      "count                                                 506  5.060000e+02   \n",
      "unique                                                506           NaN   \n",
      "top     Tidak ada orang yang keracunan karena gambar m...           NaN   \n",
      "freq                                                    1           NaN   \n",
      "mean                                                  NaN  1.921141e+18   \n",
      "std                                                   NaN  3.137390e+14   \n",
      "min                                                   NaN  1.920688e+18   \n",
      "25%                                                   NaN  1.920819e+18   \n",
      "50%                                                   NaN  1.921147e+18   \n",
      "75%                                                   NaN  1.921417e+18   \n",
      "max                                                   NaN  1.921740e+18   \n",
      "\n",
      "                                              image_url  \\\n",
      "count                                                51   \n",
      "unique                                               51   \n",
      "top     https://pbs.twimg.com/media/GqtWWBoWkAAf48F.jpg   \n",
      "freq                                                  1   \n",
      "mean                                                NaN   \n",
      "std                                                 NaN   \n",
      "min                                                 NaN   \n",
      "25%                                                 NaN   \n",
      "50%                                                 NaN   \n",
      "75%                                                 NaN   \n",
      "max                                                 NaN   \n",
      "\n",
      "       in_reply_to_screen_name lang   location  quote_count  reply_count  \\\n",
      "count                      301  506        258   506.000000   506.000000   \n",
      "unique                     182    1        162          NaN          NaN   \n",
      "top                   ARSIPAJA   in  Indonesia          NaN          NaN   \n",
      "freq                        15  506         32          NaN          NaN   \n",
      "mean                       NaN  NaN        NaN     1.247036     1.130435   \n",
      "std                        NaN  NaN        NaN    24.736397     9.230748   \n",
      "min                        NaN  NaN        NaN     0.000000     0.000000   \n",
      "25%                        NaN  NaN        NaN     0.000000     0.000000   \n",
      "50%                        NaN  NaN        NaN     0.000000     0.000000   \n",
      "75%                        NaN  NaN        NaN     0.000000     1.000000   \n",
      "max                        NaN  NaN        NaN   556.000000   178.000000   \n",
      "\n",
      "        retweet_count                                          tweet_url  \\\n",
      "count      506.000000                                                506   \n",
      "unique            NaN                                                506   \n",
      "top               NaN  https://x.com/denismalhotra/status/19217396945...   \n",
      "freq              NaN                                                  1   \n",
      "mean        52.675889                                                NaN   \n",
      "std       1083.278455                                                NaN   \n",
      "min          0.000000                                                NaN   \n",
      "25%          0.000000                                                NaN   \n",
      "50%          0.000000                                                NaN   \n",
      "75%          0.000000                                                NaN   \n",
      "max      24286.000000                                                NaN   \n",
      "\n",
      "         user_id_str    username  \n",
      "count   5.060000e+02         506  \n",
      "unique           NaN         425  \n",
      "top              NaN  attentizon  \n",
      "freq             NaN           6  \n",
      "mean    1.043631e+18         NaN  \n",
      "std     7.016990e+17         NaN  \n",
      "min     1.002434e+07         NaN  \n",
      "25%     3.104432e+09         NaN  \n",
      "50%     1.292556e+18         NaN  \n",
      "75%     1.621532e+18         NaN  \n",
      "max     1.913805e+18         NaN  \n",
      "\n",
      "Jumlah Missing Values:\n",
      "conversation_id_str          0\n",
      "created_at                   0\n",
      "favorite_count               0\n",
      "full_text                    0\n",
      "id_str                       0\n",
      "image_url                  455\n",
      "in_reply_to_screen_name    205\n",
      "lang                         0\n",
      "location                   248\n",
      "quote_count                  0\n",
      "reply_count                  0\n",
      "retweet_count                0\n",
      "tweet_url                    0\n",
      "user_id_str                  0\n",
      "username                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Membaca Dataset\n",
    "df = pd.read_csv(\"KeracunanMBG.csv\")\n",
    "df.head()\n",
    "\n",
    "print(df.describe(include='all'))  # Statistik numerik & kategorikal\n",
    "print(\"\\nJumlah Missing Values:\")\n",
    "print(df.isnull().sum())  # Cek data hilang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc0edcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id_str</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>full_text</th>\n",
       "      <th>id_str</th>\n",
       "      <th>image_url</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>lang</th>\n",
       "      <th>location</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>user_id_str</th>\n",
       "      <th>username</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1921739694569877611</td>\n",
       "      <td>Mon May 12 01:30:22 +0000 2025</td>\n",
       "      <td>2</td>\n",
       "      <td>Tidak ada orang yang keracunan karena gambar m...</td>\n",
       "      <td>1921739694569877611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>in</td>\n",
       "      <td>Jakarta Selatan, DKI Jakarta</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://x.com/denismalhotra/status/19217396945...</td>\n",
       "      <td>478829168</td>\n",
       "      <td>denismalhotra</td>\n",
       "      <td>orang keracunan gambar meme tapi orang keracun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1921369671279726677</td>\n",
       "      <td>Mon May 12 01:17:56 +0000 2025</td>\n",
       "      <td>0</td>\n",
       "      <td>@ARSIPAJA Setuju.... Begitu mau tawuran langsu...</td>\n",
       "      <td>1921736566495695282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARSIPAJA</td>\n",
       "      <td>in</td>\n",
       "      <td>milky ways</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://x.com/LL__Cool__Z/status/1921736566495...</td>\n",
       "      <td>299777181</td>\n",
       "      <td>LL__Cool__Z</td>\n",
       "      <td>setuju begitu mau tawuran langsung kasih mbg a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1921561545261359221</td>\n",
       "      <td>Mon May 12 01:15:24 +0000 2025</td>\n",
       "      <td>0</td>\n",
       "      <td>@CNNIndonesia Kasus keracunan sptnya akan terj...</td>\n",
       "      <td>1921735930580439329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CNNIndonesia</td>\n",
       "      <td>in</td>\n",
       "      <td>Kota Jogja,DIY,Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://x.com/herry_zudianto/status/1921735930...</td>\n",
       "      <td>170171658</td>\n",
       "      <td>herry_zudianto</td>\n",
       "      <td>kasus keracunan sptnya terjadi terus krn mbg d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1921409302209912880</td>\n",
       "      <td>Mon May 12 01:07:34 +0000 2025</td>\n",
       "      <td>0</td>\n",
       "      <td>@Metro_TV MBG kalian aja bikin anak2 keracunan</td>\n",
       "      <td>1921733958712303737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metro_TV</td>\n",
       "      <td>in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://x.com/Sya_dayy/status/1921733958712303737</td>\n",
       "      <td>2320223304</td>\n",
       "      <td>Sya_dayy</td>\n",
       "      <td>mbg kalian bikin anak keracunan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1921561545261359221</td>\n",
       "      <td>Mon May 12 01:02:23 +0000 2025</td>\n",
       "      <td>0</td>\n",
       "      <td>@CNNIndonesia Potensi keracunan MBG dipastikan...</td>\n",
       "      <td>1921732653566545929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CNNIndonesia</td>\n",
       "      <td>in</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://x.com/sadili69920/status/1921732653566...</td>\n",
       "      <td>1848659256679313408</td>\n",
       "      <td>sadili69920</td>\n",
       "      <td>potensi keracunan mbg dipastikan terus berlanj...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_id_str                      created_at  favorite_count  \\\n",
       "0  1921739694569877611  Mon May 12 01:30:22 +0000 2025               2   \n",
       "1  1921369671279726677  Mon May 12 01:17:56 +0000 2025               0   \n",
       "2  1921561545261359221  Mon May 12 01:15:24 +0000 2025               0   \n",
       "3  1921409302209912880  Mon May 12 01:07:34 +0000 2025               0   \n",
       "4  1921561545261359221  Mon May 12 01:02:23 +0000 2025               0   \n",
       "\n",
       "                                           full_text               id_str  \\\n",
       "0  Tidak ada orang yang keracunan karena gambar m...  1921739694569877611   \n",
       "1  @ARSIPAJA Setuju.... Begitu mau tawuran langsu...  1921736566495695282   \n",
       "2  @CNNIndonesia Kasus keracunan sptnya akan terj...  1921735930580439329   \n",
       "3     @Metro_TV MBG kalian aja bikin anak2 keracunan  1921733958712303737   \n",
       "4  @CNNIndonesia Potensi keracunan MBG dipastikan...  1921732653566545929   \n",
       "\n",
       "  image_url in_reply_to_screen_name lang                      location  \\\n",
       "0       NaN                     NaN   in  Jakarta Selatan, DKI Jakarta   \n",
       "1       NaN                ARSIPAJA   in                    milky ways   \n",
       "2       NaN            CNNIndonesia   in      Kota Jogja,DIY,Indonesia   \n",
       "3       NaN                Metro_TV   in                           NaN   \n",
       "4       NaN            CNNIndonesia   in                    Indonesia    \n",
       "\n",
       "   quote_count  reply_count  retweet_count  \\\n",
       "0            0            0              1   \n",
       "1            0            0              0   \n",
       "2            0            0              0   \n",
       "3            0            0              0   \n",
       "4            0            0              0   \n",
       "\n",
       "                                           tweet_url          user_id_str  \\\n",
       "0  https://x.com/denismalhotra/status/19217396945...            478829168   \n",
       "1  https://x.com/LL__Cool__Z/status/1921736566495...            299777181   \n",
       "2  https://x.com/herry_zudianto/status/1921735930...            170171658   \n",
       "3  https://x.com/Sya_dayy/status/1921733958712303737           2320223304   \n",
       "4  https://x.com/sadili69920/status/1921732653566...  1848659256679313408   \n",
       "\n",
       "         username                                       cleaned_text  \n",
       "0   denismalhotra  orang keracunan gambar meme tapi orang keracun...  \n",
       "1     LL__Cool__Z  setuju begitu mau tawuran langsung kasih mbg a...  \n",
       "2  herry_zudianto  kasus keracunan sptnya terjadi terus krn mbg d...  \n",
       "3        Sya_dayy                    mbg kalian bikin anak keracunan  \n",
       "4     sadili69920  potensi keracunan mbg dipastikan terus berlanj...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector = BuzzerDetector()\n",
    "df_filtered = df\n",
    "df_filtered['cleaned_text'] = df_filtered['full_text'].apply(detector.clean_text_full)\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88008008",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv('KeracunanMBGClean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
