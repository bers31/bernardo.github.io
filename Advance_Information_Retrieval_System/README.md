# ğŸ¤– Neural Information Retrieval (IR) Based on mBERT
### ğŸ” *Multilingual document retrieval powered by transformer embeddings and advanced ranking algorithms*

---

<div align="center">

<img src="https://img.shields.io/badge/build-passing-brightgreen.svg?style=for-the-badge" alt="Build Status"/>
<img src="https://img.shields.io/badge/python-3.8%2B-blue.svg?style=for-the-badge&logo=python" alt="Python Version"/>
<img src="https://img.shields.io/badge/license-MIT-orange.svg?style=for-the-badge" alt="License"/>
<img src="https://img.shields.io/badge/model-mBERT-red.svg?style=for-the-badge&logo=tensorflow" alt="mBERT"/>
<img src="https://img.shields.io/badge/demo-Streamlit-FF4B4B.svg?style=for-the-badge&logo=streamlit" alt="Streamlit"/>

</div>

---

## ğŸ“– Project Overview

<div align="center">
<img src="https://img.shields.io/badge/Status-Active%20Development-success?style=flat-square" alt="Status"/>
<img src="https://img.shields.io/badge/Type-Research%20Project-informational?style=flat-square" alt="Type"/>
<img src="https://img.shields.io/badge/Domain-Information%20Retrieval-purple?style=flat-square" alt="Domain"/>
</div>

### ğŸ¯ **Background & Motivation**

Traditional Information Retrieval (IR) systems rely heavily on statistical methods like **BM25** and **TF-IDF**. While effective, these approaches often struggle with semantic understanding and multilingual contexts. 

This project leverages the power of **mBERT (Multilingual BERT)** to generate rich, contextual embeddings that significantly enhance search quality across multiple languages. By combining state-of-the-art transformer models with advanced ranking algorithms, we create a robust end-to-end IR pipeline.

### ğŸŒŸ **Key Benefits**

- **ğŸŒ Multilingual Support**: Search across languages without retraining
- **ğŸ§  Semantic Understanding**: Context-aware document matching
- **ğŸ“Š Comprehensive Evaluation**: Multiple ranking algorithms comparison  
- **ğŸ”¬ Research-Ready**: Modular framework for IR experimentation

---

## âœ¨ Key Features

| ğŸš€ **Core Capabilities** | ğŸ› ï¸ **Advanced Algorithms** |
|---------------------------|----------------------------|
| **End-to-End IR Pipeline** from raw data to evaluation | **Cosine Similarity** (Baseline approach) |
| **Multiple Ranking Methods** comparison framework | **XGBoost** Learning-to-Rank implementation |
| **Transformer-Based Embeddings** using mBERT | **RankNet** Pairwise ranking neural network |
| **Comprehensive Metrics** (Precision, Recall, F1-Score) | **LambdaMART** Advanced ranking algorithm |

---

## ğŸ› ï¸ Technology Stack

<div align="center">
<img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python"/>
<img src="https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white" alt="Jupyter"/>
<img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white" alt="Streamlit"/>
<img src="https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white" alt="Pandas"/>
<img src="https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white" alt="NumPy"/>
<img src="https://img.shields.io/badge/scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white" alt="scikit-learn"/>
</div>

### **Core Technologies**

<table>
<thead>
<tr>
<th>Category</th>
<th>Tools & Libraries</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ğŸ Core Language</strong></td>
<td><img src="https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white" alt="Python"/></td>
<td>Main development language</td>
</tr>
<tr>
<td><strong>ğŸ“Š Data Processing</strong></td>
<td><code>pandas</code> <code>numpy</code></td>
<td>Data manipulation and analysis</td>
</tr>
<tr>
<td><strong>ğŸ” IR Framework</strong></td>
<td><code>ir_datasets</code></td>
<td>Dataset loading and management</td>
</tr>
<tr>
<td><strong>ğŸ¤– ML & Embeddings</strong></td>
<td><code>sentence-transformers</code> <code>scikit-learn</code></td>
<td>Embedding generation and similarity</td>
</tr>
<tr>
<td><strong>ğŸ† Ranking Models</strong></td>
<td><code>xgboost</code> <code>lightgbm</code></td>
<td>Advanced ranking algorithms</td>
</tr>
<tr>
<td><strong>ğŸ“ˆ Visualization</strong></td>
<td><code>streamlit</code> <code>matplotlib</code></td>
<td>Interactive demos and plots</td>
</tr>
<tr>
<td><strong>âš¡ Performance</strong></td>
<td><code>numpy</code> vectorization</td>
<td>Optimized computations</td>
</tr>
</tbody>
</table>

---

## ğŸš€ Installation & Quick Start

### **Prerequisites**
- Python 3.8 or higher
- 8GB+ RAM recommended for embedding generation
- CUDA-capable GPU (optional, for faster processing)

### **1. Clone the Repository**
```bash
git clone https://github.com/bers31/bernardo.github.io.git
cd bernardo.github.io
```

### **2. Install Dependencies**
```bash
# Create virtual environment (recommended)
python -m venv neural_ir_env
source neural_ir_env/bin/activate  # On Windows: neural_ir_env\Scripts\activate

# Install required packages
pip install -r requirements.txt
```

### **3. Data Preprocessing & ETL**
```bash
# Run ETL pipeline
python src/etl.py --input raw/ --output processed/
```

### **4. Generate Embeddings**
```bash
# Generate mBERT embeddings for queries and documents
python src/embedding.py
```

### **5. Train & Evaluate Ranking Models**
```bash
# Run all ranking algorithms
python src/ranking_cosine.py
python src/ranking_xgboost.py  
python src/ranking_ranknet.py
python src/ranking_lambdamart.py
```

### **6. Launch Interactive Demo**
```bash
# Start Streamlit application
streamlit run app.py
```

---

## ğŸ¥ Demo & Screenshots


### ğŸŒ Live Demo
[**â–º Launch Application**](https://bers31.github.io/bernardo.github.io/Advance_Information_Retrieval_System/)

![Streamlit](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)

<details>
<summary><b>ğŸ“¸ Click to view screenshots</b></summary>

<div align="center">

<p><strong>Main Dashboard</strong></p>
<img src="https://bers31.github.io/bernardo.github.io/Advance_Information_Retrieval_System/images/image5.png" alt="Main Dashboard" width="80%"/>

<p><strong>Search Results Comparison</strong></p>
<img src="https://bers31.github.io/bernardo.github.io/Advance_Information_Retrieval_System/images/image1.png" alt="Search Results" width="80%"/>

<p><strong>Performance Metrics Visualization</strong></p>
<img src="https://bers31.github.io/bernardo.github.io/Advance_Information_Retrieval_System/images/image.png" alt="Performance Metrics" width="80%"/>

</div>

</details>

---

## ğŸ“Š Project Architecture

<pre>
Raw Data Sources                  ETL Pipeline                    Embedding Layer
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸ“ Queries   â”‚              â”‚                 â”‚              â”‚                 â”‚
â”‚   Collection    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  ğŸ”„ Data       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  ğŸ¤– mBERT      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  Cleaning &     â”‚              â”‚  Encoder        â”‚
                                 â”‚  Preprocessing  â”‚              â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚                 â”‚              â”‚  Model:         â”‚
â”‚  ğŸ“‹ Documents   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  â€¢ Case Folding â”‚              â”‚  multilingual-  â”‚
â”‚   Collection    â”‚              â”‚  â€¢ Deduplicationâ”‚              â”‚  mpnet-base-v2  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  â€¢ Missing Data â”‚              â”‚                 â”‚
                                 â”‚  â€¢ Text Normali â”‚              â”‚  Output: 768-d  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚    zation       â”‚              â”‚  vectors        â”‚
â”‚  ğŸ“Š Relevance   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                 â”‚              â”‚                 â”‚
â”‚  Judgments      â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  (Qrels)        â”‚                       â”‚                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â–¼                               â–¼
                                                                           
Feature Engineering                                      Ranking Algorithms
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“Š Feature Matrix Generation           â”‚           â”‚  ğŸ“ Cosine      â”‚
â”‚                                         â”‚            â”‚  Similarity     â”‚
â”‚  Primary Features:                      â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  (Baseline)     â”‚
â”‚  â€¢ Query Embeddings (768-d)            â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â€¢ Document Embeddings (768-d)         â”‚                     â”‚
â”‚  â€¢ Cosine Similarity Scores            â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                         â”‚           â”‚  ğŸŒ³ XGBoost     â”‚
â”‚  Additional Features:                   â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Learning-to-   â”‚
â”‚  â€¢ Text Length Ratios                  â”‚            â”‚  Rank           â”‚
â”‚  â€¢ Word Count Statistics               â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â€¢ Query-Document Overlap              â”‚                     â”‚
â”‚                                         â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  ğŸ§  RankNet    â”‚
                         â”‚                             â”‚  Pairwise       â”‚â—€â”€â”€â”
                         â–¼                             â”‚  Ranking        â”‚   â”‚
                                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
Evaluation Engine                                               â”‚            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  ğŸ“ˆ Performance Metrics                â”‚            â”‚  ğŸ¯ LambdaMART  â”‚   â”‚
â”‚                                         â”‚            â”‚  Advanced LTR   â”‚â—€â”€â”€â”˜
â”‚  Per-Query Metrics:                     â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Algorithm      â”‚
â”‚  â€¢ Precision @ K                        â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â€¢ Recall @ K                           â”‚                     â”‚
â”‚  â€¢ F1-Score @ K                         â”‚                     â”‚
â”‚                                         â”‚                     â–¼
â”‚  Aggregate Metrics:                     â”‚            
â”‚  â€¢ Mean Average Precision (MAP)         â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â€¢ Normalized DCG (NDCG)                â”‚            â”‚  ğŸ“Š Results     â”‚
â”‚  â€¢ Cross-Model Comparison               â”‚            â”‚  Comparison &   â”‚
â”‚                                         â”‚            â”‚  Best Model     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  Selection      â”‚
                         â”‚                             â”‚                 â”‚
                         â–¼                             â”‚  Winner:        â”‚
                                                       â”‚  ğŸ† LambdaMART  â”‚
User Interface Layer                                   â”‚  F1: 0.817      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ ğŸ–¥ï¸ Streamlit  â”‚ â”‚ ğŸ““ Jupyter    â”‚ â”‚ ğŸ”§ CLI Tools    â”‚
â”‚ Interactive   â”‚ â”‚ Notebooks     â”‚ â”‚ â€¢ etl.py        â”‚
â”‚ Web Dashboard â”‚ â”‚ Research &    â”‚ â”‚ â€¢ embedding.py  â”‚
â”‚ â€¢ Live Demo   â”‚ â”‚ Development   â”‚ â”‚ â€¢ ranking_*.py  â”‚
â”‚ â€¢ Visualizati â”‚ â”‚ â€¢ Data Explor â”‚ â”‚ â€¢ evaluate.py   â”‚
â”‚   on          â”‚ â”‚   ation       â”‚ â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</pre>

### **System Flow:**
1. **ğŸ“ Data Input** â†’ Vaswani Dataset via `ir_datasets`
2. **ğŸ”„ ETL Pipeline** â†’ Data cleaning & preprocessing
3. **ğŸ¤– mBERT Encoding** â†’ Generate contextual embeddings
4. **ğŸ“Š Feature Engineering** â†’ Cosine similarity + additional features
5. **ğŸ† Ranking Models** â†’ Multiple algorithm comparison
6. **ğŸ“ˆ Evaluation** â†’ Precision, Recall, F1-Score metrics

---

## ğŸ—“ï¸ Development Roadmap

<table>
<thead>
<tr>
<th><strong>Phase</strong></th>
<th><strong>Milestone</strong></th>
<th><strong>Target Date</strong></th>
<th><strong>Status</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Phase 1</strong></td>
<td>Data Pipeline & ETL</td>
<td>âœ… Completed</td>
<td><img src="https://img.shields.io/badge/100%25-success" alt="100% Complete"/></td>
</tr>
<tr>
<td><strong>Phase 2</strong></td>
<td>mBERT Integration</td>
<td>âœ… Completed</td>
<td><img src="https://img.shields.io/badge/100%25-success" alt="100% Complete"/></td>
</tr>
<tr>
<td><strong>Phase 3</strong></td>
<td>Baseline Implementation</td>
<td>âœ… Completed</td>
<td><img src="https://img.shields.io/badge/100%25-success" alt="100% Complete"/></td>
</tr>
<tr>
<td><strong>Phase 4</strong></td>
<td>Advanced Ranking Models</td>
<td>ğŸ”„ In Progress</td>
<td><img src="https://img.shields.io/badge/80%25-yellow" alt="80% Complete"/></td>
</tr>
<tr>
<td><strong>Phase 5</strong></td>
<td>Performance Optimization</td>
<td>ğŸ“… Q1 2026</td>
<td><img src="https://img.shields.io/badge/Planning-blue" alt="Planning"/></td>
</tr>
<tr>
<td><strong>Phase 6</strong></td>
<td>Production Deployment</td>
<td>ğŸ“… Q2 2026</td>
<td><img src="https://img.shields.io/badge/Planning-blue" alt="Planning"/></td>
</tr>
</tbody>
</table>

---

## ğŸ“ˆ Performance Metrics

<div align="center">

<table>
<thead>
<tr>
<th><strong>Algorithm</strong></th>
<th><strong>Avg Precision</strong></th>
<th><strong>Avg Recall</strong></th>
<th><strong>Avg F1-Score</strong></th>
<th><strong>Training Time</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Cosine Similarity</strong></td>
<td>0.742</td>
<td>0.681</td>
<td>0.710</td>
<td>~2 min</td>
</tr>
<tr>
<td><strong>XGBoost</strong></td>
<td>0.798</td>
<td>0.756</td>
<td>0.776</td>
<td>~15 min</td>
</tr>
<tr>
<td><strong>RankNet</strong></td>
<td>0.812</td>
<td>0.773</td>
<td>0.792</td>
<td>~25 min</td>
</tr>
<tr>
<td><strong>LambdaMART</strong></td>
<td><strong>0.834</strong></td>
<td><strong>0.801</strong></td>
<td><strong>0.817</strong></td>
<td>~20 min</td>
</tr>
</tbody>
</table>

</div>

<blockquote>
<p><strong>Note</strong>: Results based on Vaswani test collection. Performance may vary with different datasets.</p>
</blockquote>

---

## ğŸ¤ Contributing

We welcome contributions from the community! Here's how you can help:

<details>
<summary><b>ğŸ› ï¸ Development Guidelines</b></summary>

### **Getting Started**
1. **Fork** the repository
2. **Create** a feature branch: `git checkout -b feature/amazing-feature`
3. **Commit** your changes: `git commit -m 'Add some amazing feature'`
4. **Push** to the branch: `git push origin feature/amazing-feature`
5. **Open** a Pull Request

### **Code Standards**
- Follow **PEP 8** Python style guidelines
- Add **docstrings** to all functions and classes
- Include **unit tests** for new features
- Update **documentation** as needed

### **Areas for Contribution**
- ğŸ› **Bug fixes** and performance improvements
- ğŸ“Š **New ranking algorithms** implementation
- ğŸŒ **Additional language support**
- ğŸ“š **Documentation** enhancements
- ğŸ§ª **Test coverage** expansion

</details>

---

## ğŸ“„ **License**

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

```
MIT License

Copyright (c) 2024 Bernardo - Universitas Diponegoro

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
```

## ğŸ“« Contact & Connect

<p align="center">
<strong>ğŸ‘¨â€ğŸ’» Bernardo - Computer Science Student</strong><br/>
Universitas Diponegoro ğŸ“
</p>

<p align="center">
<a href="https://linkedin.com/in/bernardo-sunia/">
<img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn">
</a>
<a href="https://mail.google.com/mail/?view=cm&fs=1&to=suniabernardo@gmail.com">
<img src="https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white" alt="Email">
</a>
<a href="https://github.com/bers31">
<img src="https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white" alt="GitHub">
</a>
<a href="https://bit.ly/bernardo-my_portfolio">
<img src="https://img.shields.io/badge/Portfolio-255E63?style=for-the-badge&logo=About.me&logoColor=white" alt="Portfolio">
</a>
</p>

<p align="center">
â­ <strong>If you found this project helpful, please give it a star!</strong> â­
</p>

<p align="center">
<em>Made with â¤ï¸ by <a href="https://github.com/bers31">Bernardo</a> at Universitas Diponegoro</em><br/>
<img src="https://visitor-badge.laobi.icu/badge?page_id=bers31.bernardo.github.io" alt="Visitor Count">
</p>

---

### Full Screenshots
![Screenshot 1](images/image.png)
![Screenshot 2](images/image1.png)
![Screenshot 3](images/image2.png)
![Screenshot 4](images/image3.png)
![Screenshot 5](images/image4.png)
![Screenshot 6](images/image5.png)

### Conclusion
This project demonstrates the implementation of a modern Information Retrieval system that combines deep learning and machine learning techniques to deliver more accurate and relevant search results compared to traditional keyword-based approaches.
